import { log } from '@/utils/logger';
import { buildSystemPrompt } from '@/prompts/system-prompt';
import { ConversationContextService } from './conversation-context.service';

export interface MessageConfig {
  shouldSplit: boolean;
  messages: string[];
  delays: number[];
  typingDuration: number;
}

export interface GeminiAIResponse {
  actionType: 'food_suggestion' | 'debt_tracking' | 'conversation' | 'error';
  response: string;
  messageConfig?: MessageConfig;
  data?: {
    // For food suggestions
    foodName?: string;
    description?: string;
    ingredients?: string[];
    tips?: string;
    
    // For debt tracking
    debtorUsername?: string;
    creditorUsername?: string;
    amount?: number;
    currency?: string;
    description?: string;
    action?: 'create' | 'pay' | 'list' | 'check';
    
    // For conversation
    conversationResponse?: string;
  };
  success: boolean;
  error?: string;
}

export class GeminiAIService {
  private apiKey: string;
  private baseUrl = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent';
  private conversationContext: ConversationContextService;

  constructor(apiKey: string, conversationContext: ConversationContextService) {
    this.apiKey = apiKey;
    this.conversationContext = conversationContext;
  }

  /**
   * Process user message with Gemini AI to determine action and response
   */
  async processMessage(
    userMessage: string, 
    chatMembers: string[], 
    userId: string,
    chatId: string,
    username?: string,
    context?: any
  ): Promise<GeminiAIResponse> {
    try {
      // T·∫°o context string t·ª´ conversation history
      let contextString = '';
      if (context && (context.messages.length > 0 || context.summaries.length > 0)) {
        contextString = this.conversationContext.createContextForAI(context.messages, context.summaries);
        
        log.debug('Using conversation context', {
          userId, chatId,
          messageCount: context.messages.length,
          summaryCount: context.summaries.length,
          totalTokens: context.totalTokens,
          contextStatus: context.contextStatus
        });
      }

      // Build system prompt v·ªõi conversation context
      const systemPrompt = buildSystemPrompt(chatMembers, userId, username, context?.messages || []);
      
      const requestBody = {
        contents: [{
          parts: [{
            text: `${systemPrompt}

${contextString ? `L·ªäCH S·ª¨ CU·ªòC TR√í CHUY·ªÜN:\n${contextString}\n` : ''}

USER MESSAGE M·ªöI: "${userMessage}"

D·ª±a tr√™n ${contextString ? 'l·ªãch s·ª≠ v√† ' : ''}tin nh·∫Øn m·ªõi, ph√¢n t√≠ch v√† tr·∫£ v·ªÅ JSON:
{
  "actionType": "food_suggestion" | "debt_tracking" | "conversation",
  "response": "C√¢u tr·∫£ l·ªùi t·ª± nhi√™n nh∆∞ con ng∆∞·ªùi nh·∫Øn tin, KH√îNG emoji",
  "messageConfig": {
    "shouldSplit": true/false,
    "messages": ["Tin nh·∫Øn 1", "Tin nh·∫Øn 2", "Tin nh·∫Øn 3..."],
    "delays": [1000, 2000, 1500],
    "typingDuration": 2000
  },
  "data": {
    // N·∫øu l√† food_suggestion:
    "foodName": "T√™n m√≥n ƒÉn",
    "description": "C√°ch l√†m ƒë∆°n gi·∫£n cho sinh vi√™n",
    "ingredients": ["Nguy√™n li·ªáu d·ªÖ ki·∫øm, r·∫ª"],
    "tips": "M·∫πo n·∫•u n∆∞·ªõng"
    
    // N·∫øu l√† debt_tracking:
    "debtorUsername": "Ng∆∞·ªùi n·ª£",
    "creditorUsername": "Ng∆∞·ªùi cho vay", 
    "amount": s·ªë ti·ªÅn,
    "currency": "VND",
    "description": "M√¥ t·∫£ kho·∫£n n·ª£",
    "action": "create" | "pay" | "list" | "check"
    
    // N·∫øu l√† conversation:
    "conversationResponse": "Ph·∫£n h·ªìi t·ª± nhi√™n"
  }
}

V√ç D·ª§ response cho food_suggestion:
"Th·ª≠ l√†m m√¨ t√¥m tr·ª©ng ƒëi b·∫°n. ƒêun n∆∞·ªõc s√¥i cho m√¨ v√†o, ƒë·∫≠p tr·ª©ng v√†o l√∫c s·∫Øp ch√≠n. Th√™m ch√∫t rau c·∫£i ho·∫∑c h√†nh l√° cho ƒë·∫πp m·∫Øt. V·ª´a nhanh v·ª´a no b·ª•ng."

V√ç D·ª§ response cho conversation:
"Ch√†o b·∫°n! H√¥m nay th·∫ø n√†o r·ªìi?"

KH√îNG ƒë∆∞·ª£c d√πng emoji, kh√¥ng formal, vi·∫øt nh∆∞ tin nh·∫Øn b·∫°n b√®`
          }]
        }],
        generationConfig: {
          temperature: 0.7,
          topK: 1,
          topP: 1,
          maxOutputTokens: 1000,
        }
      };

      log.debug('Calling Gemini AI for message processing', { 
        messageLength: userMessage.length,
        memberCount: chatMembers.length,
        userId,
        chatId,
        hasContext: !!contextString,
        contextLength: contextString.length,
        totalTokens: context?.totalTokens || 0
      });

      const startTime = Date.now();
      const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-goog-api-key': this.apiKey,
        },
        body: JSON.stringify(requestBody),
      });

      const processingTime = Date.now() - startTime;

      if (!response.ok) {
        const errorText = await response.text();
        log.error('Gemini AI API error', undefined, {
          status: response.status,
          statusText: response.statusText,
          error: errorText,
          processingTime
        });
        return {
          actionType: 'error',
          response: 'Xin l·ªói, c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω tin nh·∫Øn c·ªßa b·∫°n.',
          success: false,
          error: `API Error: ${response.status}`
        };
      }

      const data = await response.json();
      
      if (!data.candidates || data.candidates.length === 0) {
        log.error('No candidates in Gemini response', undefined, { response: data, processingTime });
        return {
          actionType: 'error',
          response: 'Kh√¥ng th·ªÉ x·ª≠ l√Ω tin nh·∫Øn c·ªßa b·∫°n l√∫c n√†y.',
          success: false,
          error: 'No AI response generated'
        };
      }

      const aiResponseText = data.candidates[0]?.content?.parts[0]?.text || '';
      
      if (!aiResponseText.trim()) {
        log.error('Empty response from Gemini', undefined, { data, processingTime });
        return {
          actionType: 'error',
          response: 'Ph·∫£n h·ªìi t·ª´ AI b·ªã tr·ªëng.',
          success: false,
          error: 'Empty AI response'
        };
      }

      // Parse JSON response from AI
      try {
        const jsonMatch = aiResponseText.match(/\{[\s\S]*\}/);
        if (!jsonMatch) {
          log.error('No JSON found in AI response', undefined, { aiResponseText, processingTime });
          return {
            actionType: 'conversation',
            response: aiResponseText,
            data: { conversationResponse: aiResponseText },
            success: true
          };
        }

        const aiResponse = JSON.parse(jsonMatch[0]);
        
        // LOG CHI TI·∫æT RESPONSE T·ª™ GEMINI
        log.info('ü§ñ GEMINI RESPONSE DEBUG', {
          userId, chatId, processingTime,
          rawAiText: aiResponseText.substring(0, 200),
          parsedResponse: {
            actionType: aiResponse.actionType,
            response: aiResponse.response,
            hasMessageConfig: !!aiResponse.messageConfig,
            messageConfig: aiResponse.messageConfig,
            hasData: !!aiResponse.data,
            dataKeys: aiResponse.data ? Object.keys(aiResponse.data) : []
          }
        });
        
        // Validate that we have the required response field
        if (!aiResponse.response) {
          log.error('No response field in AI JSON', undefined, { aiResponse, processingTime });
          return {
            actionType: 'conversation',
            response: aiResponseText,
            data: { conversationResponse: aiResponseText },
            success: true
          };
        }

        log.info('Gemini AI response processed successfully', { 
          actionType: aiResponse.actionType,
          responseLength: aiResponse.response?.length || 0,
          processingTime,
          userId,
          chatId,
          hasContext: !!contextString,
          messageConfigPresent: !!aiResponse.messageConfig,
          shouldSplit: aiResponse.messageConfig?.shouldSplit || false
        });

        // Auto-generate messageConfig if AI didn't provide one
        let messageConfig = aiResponse.messageConfig;
        if (!messageConfig) {
          log.warn('Gemini kh√¥ng tr·∫£ v·ªÅ messageConfig, t·ª± ƒë·ªông t·∫°o', {
            userId, chatId,
            responseLength: aiResponse.response?.length || 0,
            actionType: aiResponse.actionType
          });
          
          // T·ª± ƒë·ªông quy·∫øt ƒë·ªãnh c√≥ n√™n chia tin nh·∫Øn kh√¥ng
          const shouldAutoSplit = this.shouldAutoSplitMessage(aiResponse.response, aiResponse.actionType);
          
          if (shouldAutoSplit) {
            messageConfig = this.createAutoMessageConfig(aiResponse.response, aiResponse.actionType);
            log.info('ƒê√£ t·∫°o messageConfig t·ª± ƒë·ªông', {
              userId, chatId,
              shouldSplit: messageConfig.shouldSplit,
              messageCount: messageConfig.messages.length,
              actionType: aiResponse.actionType
            });
          }
        }

        // Return the parsed response with proper structure
        return {
          actionType: aiResponse.actionType || 'conversation',
          response: aiResponse.response, // This is the clean text response
          messageConfig: messageConfig,
          data: aiResponse.data || {},
          success: true
        };

      } catch (parseError: any) {
        log.error('Error parsing AI JSON response', parseError, { 
          aiResponseText: aiResponseText.substring(0, 200),
          processingTime 
        });
        
        // Fallback to treating as conversation
        return {
          actionType: 'conversation',
          response: aiResponseText,
          data: { conversationResponse: aiResponseText },
          success: true
        };
      }

    } catch (error: any) {
      log.error('Error calling Gemini AI', error, {
        errorMessage: error.message,
        errorStack: error.stack,
        userId
      });
      
      return {
        actionType: 'error',
        response: 'C√≥ l·ªói x·∫£y ra khi k·∫øt n·ªëi v·ªõi AI. Vui l√≤ng th·ª≠ l·∫°i sau.',
        success: false,
        error: error.message
      };
    }
  }

  /**
   * T·ª± ƒë·ªông quy·∫øt ƒë·ªãnh c√≥ n√™n chia tin nh·∫Øn kh√¥ng (theo lu·∫≠t 20 t·ª´)
   */
  private shouldAutoSplitMessage(response: string, actionType: string): boolean {
    if (!response) return false;
    
    // ƒê·∫øm s·ªë t·ª´ thay v√¨ k√Ω t·ª±
    const wordCount = response.trim().split(/\s+/).length;
    
    // Ch·ªâ g·ª≠i 1 tin n·∫øu TH·∫¨T NG·∫ÆN (<10 t·ª´) v√† l√† x√°c nh·∫≠n ƒë∆°n gi·∫£n
    if (wordCount < 10 && (
      response.match(/^(ok|ƒë∆∞·ª£c|·ª´m|ch√†o|hi|hello|bye|c·∫£m ∆°n|thanks)/i) ||
      actionType === 'confirmation'
    )) {
      return false;
    }
    
    // T·∫•t c·∫£ c√°c tr∆∞·ªùng h·ª£p kh√°c ƒë·ªÅu chia nh·ªè
    return true;
  }
  
  /**
   * T·ª± ƒë·ªông t·∫°o messageConfig cho response (theo lu·∫≠t 20 t·ª´/tin)
   */
  private createAutoMessageConfig(response: string, actionType: string): MessageConfig {
    // H√†m helper ƒë·ªÉ chia text th√†nh chunks 20 t·ª´
    const splitIntoChunks = (text: string, maxWords: number = 20): string[] => {
      const words = text.trim().split(/\s+/);
      const chunks: string[] = [];
      
      for (let i = 0; i < words.length; i += maxWords) {
        chunks.push(words.slice(i, i + maxWords).join(' '));
      }
      
      return chunks;
    };
    
    if (actionType === 'food_suggestion') {
      // Chia food suggestion v·ªõi prefix t·ª± nhi√™n
      const mainContent = splitIntoChunks(response, 15); // ƒê·ªÉ l·∫°i ch·ªó cho prefix
      const messageCount = 2 + mainContent.length;
      return {
        shouldSplit: true,
        messages: [
          '·ªú ƒë·ªÉ em nghƒ© c√°i...',
          ...mainContent,
          'D·ªÖ m√† ngon ƒë√≥ b·∫°n!'
        ].filter(m => m.length > 1),
        delays: Array(messageCount).fill(0).map(() => 
          Math.floor(Math.random() * 600) + 800 // 0.8-1.4s random
        ),
        typingDuration: 800 // Gi·∫£m typing time
      };
    }
    
    if (actionType === 'debt_tracking') {
      // Chia debt tracking
      const mainContent = splitIntoChunks(response, 15);
      const messageCount = 1 + mainContent.length;
      return {
        shouldSplit: true,
        messages: [
          'ƒê·ªÉ em check l·∫°i...',
          ...mainContent
        ],
        delays: Array(messageCount).fill(0).map(() => 
          Math.floor(Math.random() * 400) + 600 // 0.6-1.0s random
        ),
        typingDuration: 600
      };
    }
    
    // Conversation - chia th√†nh chunks 20 t·ª´
    const chunks = splitIntoChunks(response, 20);
    
    if (chunks.length === 1) {
      // N·∫øu v·∫´n ch·ªâ 1 chunk, c√≥ th·ªÉ chia theo d·∫•u ch·∫•m
      const sentences = response.split(/[.!?]+/).filter(s => s.trim().length > 0);
      if (sentences.length > 1) {
        const shortChunks = sentences.map(s => {
          const words = s.trim().split(/\s+/);
          return words.length > 20 ? splitIntoChunks(s.trim(), 20) : [s.trim()];
        }).flat();
        
        return {
          shouldSplit: true,
          messages: shortChunks,
          delays: Array(shortChunks.length).fill(0).map(() => 
            Math.floor(Math.random() * 500) + 600 // 0.6-1.1s random
          ),
          typingDuration: 700
        };
      }
    }
    
    // Multiple chunks
    return {
      shouldSplit: true,
      messages: chunks,
      delays: Array(chunks.length).fill(0).map(() => 
        Math.floor(Math.random() * 500) + 600 // 0.6-1.1s random  
      ),
      typingDuration: 700
    };
  }

  /**
   * Build system prompt for Gemini AI
   */
  private buildSystemPrompt(chatMembers: string[], userId: string, username?: string): string {
    return `B·∫°n l√† m·ªôt AI bot th√¥ng minh h·ªó tr·ª£ ng∆∞·ªùi Vi·ªát Nam trong group chat Telegram. Nhi·ªám v·ª• ch√≠nh:

1. RANDOM M√ìN ƒÇN: G·ª£i √Ω m√≥n ƒÉn Vi·ªát Nam ngon, d·ªÖ l√†m
2. GHI N·ª¢: Theo d√µi c√°c kho·∫£n n·ª£ gi·ªØa th√†nh vi√™n nh√≥m  
3. TR√í CHUY·ªÜN: Ph·∫£n h·ªìi th√¢n thi·ªán, t·ª± nhi√™n

TH√ÄNH VI√äN NH√ìM HI·ªÜN T·∫†I: ${chatMembers.join(', ')}
USER ƒêANG CHAT: ${username || userId}

H∆Ø·ªöNG D·∫™N PH√ÇN T√çCH:

FOOD_SUGGESTION - Khi user:
- H·ªèi "ƒÉn g√¨", "m√≥n g√¨ ngon", "ƒë√≥i b·ª•ng"
- Y√™u c·∫ßu g·ª£i √Ω m√≥n ƒÉn
- N√≥i v·ªÅ ƒë·ªì ƒÉn, n·∫•u n∆∞·ªõng
‚Üí G·ª£i √Ω m√≥n ph√π h·ª£p sinh vi√™n t·ª± n·∫•u, nguy√™n li·ªáu ƒë∆°n gi·∫£n, d·ªÖ ki·∫øm

DEBT_TRACKING - Khi user:
- "A n·ª£ B 50k", "t√¥i n·ª£ X 100 ngh√¨n" 
- "A tr·∫£ n·ª£ B", "ƒë√£ tr·∫£ ti·ªÅn cho C"
- "ai n·ª£ ai", "ki·ªÉm tra n·ª£"
- ƒê·ªÅ c·∫≠p ƒë·∫øn ti·ªÅn b·∫°c, vay m∆∞·ª£n, n·ª£ n·∫ßn
‚Üí Ph√¢n t√≠ch WHO owes WHO how much, action type

CONVERSATION - C√°c tr∆∞·ªùng h·ª£p kh√°c:
- Ch√†o h·ªèi, tr√≤ chuy·ªán b√¨nh th∆∞·ªùng
- H·ªèi th√¥ng tin, c√¢u h·ªèi chung
- Kh√¥ng li√™n quan food hay debt
‚Üí Tr·∫£ l·ªùi th√¢n thi·ªán, t·ª± nhi√™n nh∆∞ con ng∆∞·ªùi

QUAN TR·ªåNG:
- LU√îN tr·∫£ v·ªÅ JSON h·ª£p l·ªá
- Ph·∫£n h·ªìi t·ª± nhi√™n nh∆∞ con ng∆∞·ªùi nh·∫Øn tin, KH√îNG d√πng emoji
- V·ªõi food: ∆Øu ti√™n m√≥n d·ªÖ n·∫•u cho sinh vi√™n, nguy√™n li·ªáu r·∫ª, d·ªÖ ki·∫øm
- V·ªõi debt: Nh·∫≠n d·∫°ng ch√≠nh x√°c username t·ª´ danh s√°ch th√†nh vi√™n
- S·ªë ti·ªÅn format: ch·ªâ s·ªë, kh√¥ng ch·ªØ (50000 thay v√¨ "50k")
- Response ph·∫£i ng·∫Øn g·ªçn, th√¢n thi·ªán, kh√¥ng formal`;
  }
}